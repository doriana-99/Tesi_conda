{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQCTd9yqDBsG",
        "outputId": "60270ac4-f229-4368-8bdf-4ecf0ee91828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "CUDA Available: True\n"
          ]
        }
      ],
      "source": [
        "# Installa le librerie necessarie\n",
        "!pip install pandas transformers tqdm torch\n",
        "\n",
        "# Assicurati che la GPU sia attiva su Colab (Opzionale)\n",
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0TPz9JJGFdo",
        "outputId": "bae9a2ea-d8f6-452e-824a-f5d0c7c6db3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "HF_TOKEN = \"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\"\n",
        "login(token=HF_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5Fp5mFGF5mp",
        "outputId": "4d9f1c8b-f9b7-442e-a632-8f80c28f572f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista di modelli\n",
        "models = [\n",
        "    #\"mistralai/Mistral-7B-Instruct-v0.1\"   # mistral base: già fatto\n",
        "    #\"mii-community/zefiro-7b-base-ITA\"  # mistral italiano\n",
        "    # \"BioMistral/BioMistral-7B\"  # mistral medico\n",
        "    #\"meta-llama/Meta-Llama-3-8B-Instruct\"  # llama base\n",
        "    #\"swap-uniba/LLaMAntino-3-ANITA-8B-Inst-DPO-ITA\"  # llama italiano\n",
        "    #\"ContactDoctor/Bio-Medical-Llama-3-8B\"  # llama medico\n",
        "    # \"google/gemma-2-9b-it\"  # gemma base\n",
        "     \"Shaleen123/gemma2-9b-medical\" # gemma medico\n",
        "]\n",
        "\n",
        "# Lista di categorie\n",
        "categories = [\n",
        "    \"Medicina Generale\"\n",
        "    # \"Allergologia e immunologia clin\"\n",
        "    # \"Dermatologia e venereologia\"\n",
        "    # \"Ematologia\"\n",
        "    # \"Endocrinologia e malattie del m\"\n",
        "    # \"Gastroenterologia\"\n",
        "    # \"Geriatria\"\n",
        "    # \"Malattie dell'apparato cardiova\"\n",
        "    # \"Malattie dell'apparato respirat\"\n",
        "    # \"Malattie infettive\"\n",
        "    # \"Medicina dello sport\"\n",
        "    # \"Medicina d'emergenza-urgenza\"\n",
        "    # \"Medicina di comunità\"\n",
        "    # \"Medicina interna\"\n",
        "    # \"Medicina termale\"\n",
        "    # \"Medicina tropicale\"\n",
        "    # \"Nefrologia\"\n",
        "    # \"Neurologia\"\n",
        "    # \"Neuropsichiatria infantile\"\n",
        "    # \"Oncologia\"\n",
        "    # \"Pediatria\"\n",
        "    # \"Psichiatria\"\n",
        "    # \"Reumatologia\"\n",
        "    # \"Scienza dell'alimentazione\"\n",
        "    # \"Cardiochirurgia\"\n",
        "    # \"Chirurgia dell'apparato digeren\"\n",
        "    # \"Chirurgia generale\"\n",
        "    # \"Chirurgia maxillo-facciale\"\n",
        "    # \"Chirurgia pediatrica\"\n",
        "    # \"Chirurgia plastica ricostruttiv\"\n",
        "    # \"Chirurgia toracica\"\n",
        "    # \"Chirurgia vascolare\"\n",
        "    # \"Ginecologia ed Ostetricia\"\n",
        "    # \"Neurochirurgia\"\n",
        "    # \"Oftalmologia\"\n",
        "    # \"Ortopedia e traumatologia\"\n",
        "    # \"Otorinolaringoiatra\"\n",
        "    # \"Urologia\"\n",
        "    # \"Anatomia patologica\"\n",
        "    # \"Anestesia e Rianimazione e Tera\"\n",
        "    # \"Audiologia e foniatria\"\n",
        "    # \"Biochimica clinica\"\n",
        "    # \"Farmacologia\"\n",
        "    # \"Genetica medica\"\n",
        "    # \"Igiene e medicina preventiva\"\n",
        "    # \"Medicina del lavoro\"\n",
        "    # \"Medicina fisica e riabilitativa\"\n",
        "    # \"Medicina legale\"\n",
        "    # \"Medicina nucleare\"\n",
        "    # \"Microbiologia e virologia\"\n",
        "    # \"Patologia clinica\"\n",
        "    # \"Radiodiagnostica\"\n",
        "    # \"Radioterapia\"\n",
        "    # \"Statistica sanitaria e Biometri\"\n",
        "    # \"Tossicologia medica\"\n",
        "    # \"Malattie dell'apparato digerent\"\n",
        "    # \"Malattie infettive e tropicali\"\n",
        "    # \"Chirurgia dell'apparato digeren\"\n",
        "    # \"Medicina dello sport e dell'ese\"\n",
        "    # \"Medicina di comunità e delle cu\"\n",
        "    # \"Oncologia medica\"\n",
        "    # \"Anestesia, Rianimazione, Terapi\"\n",
        "    # \"Patologia Clinica e Biochimica\"\n",
        "    # \"Farmacologia e Tossicologia Cli\"\n",
        "]\n",
        "\n",
        "# Percorso del file Excel\n",
        "excel_path = \"/content/DataExtraction.xlsx\"\n",
        "\n",
        "# Loop attraverso tutti i modelli e categorie\n",
        "for model in models:\n",
        "    for category in categories:\n",
        "        command = f'python script_MC_new.py --excel_path \"{excel_path}\" --category \"{category}\" --model \"{model}\"'\n",
        "        print(f\"Esecuzione per modello: {model}, categoria: {category}\")\n",
        "        print(f\"Comando: {command}\")\n",
        "        !{command}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zk8G7vSZsiS",
        "outputId": "d68463f7-9b14-4438-9750-b1ca1ea6163c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esecuzione per modello: Shaleen123/gemma2-9b-medical, categoria: Medicina Generale\n",
            "Comando: python script_MC_new.py --excel_path \"/content/DataExtraction.xlsx\" --category \"Medicina Generale\" --model \"Shaleen123/gemma2-9b-medical\"\n",
            "2024-09-04 13:20:54.648943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-04 13:20:54.668949: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-04 13:20:54.674987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-04 13:20:54.689429: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-04 13:20:55.958208: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Sono in script_MC_new...\n",
            "Initializing the model...\n",
            "config.json: 100% 1.38k/1.38k [00:00<00:00, 7.22MB/s]\n",
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/quantizers/auto.py:167: UserWarning: You passed `quantization_config` or equivalent parameters to `from_pretrained` but the model you're loading already has a `quantization_config` attribute. The `quantization_config` from the model will be used.\n",
            "  warnings.warn(warning_msg)\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "model.safetensors.index.json: 100% 181k/181k [00:00<00:00, 2.80MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/4.98G [00:00<00:50, 99.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.98G [00:00<00:38, 128MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.98G [00:00<00:32, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/4.98G [00:00<00:27, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.98G [00:00<00:25, 191MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 147M/4.98G [00:00<00:24, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.98G [00:00<00:23, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 210M/4.98G [00:01<00:22, 207MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.98G [00:01<00:22, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 273M/4.98G [00:01<00:22, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.98G [00:01<00:22, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 336M/4.98G [00:01<00:22, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 367M/4.98G [00:01<00:21, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.98G [00:01<00:21, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 430M/4.98G [00:02<00:21, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.98G [00:02<00:21, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.98G [00:02<00:22, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 514M/4.98G [00:02<00:21, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 535M/4.98G [00:03<00:46, 95.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 556M/4.98G [00:03<00:41, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.98G [00:03<00:32, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.98G [00:03<00:29, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 640M/4.98G [00:03<00:26, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/4.98G [00:03<00:24, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 703M/4.98G [00:03<00:22, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.98G [00:04<00:21, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 765M/4.98G [00:04<00:21, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.98G [00:04<00:20, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 828M/4.98G [00:04<00:20, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.98G [00:04<00:19, 208MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 891M/4.98G [00:04<00:19, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.98G [00:04<00:19, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.98G [00:05<00:19, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.98G [00:05<00:18, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.02G/4.98G [00:05<00:18, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.98G [00:05<00:18, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.08G/4.98G [00:05<00:18, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.98G [00:05<00:18, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.14G/4.98G [00:06<00:18, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.98G [00:06<00:19, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.98G [00:06<00:17, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.98G [00:06<00:16, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.27G/4.98G [00:06<00:17, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.98G [00:06<00:16, 218MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.33G/4.98G [00:06<00:16, 215MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.98G [00:11<02:42, 22.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.38G/4.98G [00:11<02:18, 26.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.41G/4.98G [00:11<01:59, 30.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.43G/4.98G [00:12<01:41, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.98G [00:12<01:32, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.98G [00:12<01:25, 41.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.98G [00:12<01:20, 43.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.47G/4.98G [00:12<01:11, 49.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.98G [00:13<01:08, 51.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.49G/4.98G [00:13<01:00, 57.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.98G [00:13<00:58, 59.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.98G [00:13<00:54, 63.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.53G/4.98G [00:13<00:41, 83.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.98G [00:13<00:32, 107MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.58G/4.98G [00:13<00:23, 142MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.61G/4.98G [00:14<00:19, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.98G [00:14<00:17, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.68G/4.98G [00:14<00:16, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.71G/4.98G [00:14<00:16, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.98G [00:14<00:15, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.98G [00:14<00:15, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.78G/4.98G [00:14<00:15, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.80G/4.98G [00:14<00:15, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.98G [00:15<00:14, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.87G/4.98G [00:15<00:14, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.98G [00:15<00:14, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.93G/4.98G [00:15<00:14, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.98G [00:15<00:14, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.99G/4.98G [00:15<00:14, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.98G [00:15<00:13, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.06G/4.98G [00:16<00:13, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.09G/4.98G [00:16<00:13, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.98G [00:16<00:13, 212MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.98G [00:16<00:18, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.18G/4.98G [00:16<00:16, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.20G/4.98G [00:16<00:15, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.98G [00:17<00:14, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.98G [00:17<00:14, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.28G/4.98G [00:17<00:14, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.30G/4.98G [00:17<00:17, 154MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.32G/4.98G [00:17<00:17, 149MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.34G/4.98G [00:21<02:25, 18.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.36G/4.98G [00:21<01:46, 24.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.98G [00:21<01:09, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.41G/4.98G [00:21<00:54, 47.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.98G [00:21<00:38, 66.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.46G/4.98G [00:22<00:31, 79.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.98G [00:22<00:26, 92.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.98G [00:22<00:23, 106MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.53G/4.98G [00:22<00:20, 122MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.56G/4.98G [00:22<00:16, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.98G [00:22<00:14, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.62G/4.98G [00:22<00:12, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.65G/4.98G [00:22<00:12, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.68G/4.98G [00:23<00:11, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.72G/4.98G [00:23<00:11, 201MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.75G/4.98G [00:23<00:10, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.98G [00:23<00:12, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.81G/4.98G [00:23<00:12, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.83G/4.98G [00:24<00:14, 147MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.98G [00:24<00:14, 150MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.87G/4.98G [00:24<00:16, 126MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.98G [00:24<00:18, 114MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.92G/4.98G [00:24<00:20, 98.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.94G/4.98G [00:25<00:26, 78.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.98G [00:25<00:25, 80.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.97G/4.98G [00:25<00:20, 98.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 3.00G/4.98G [00:25<00:18, 109MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.02G/4.98G [00:26<00:21, 91.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.98G [00:26<00:21, 88.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.05G/4.98G [00:26<00:23, 81.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.98G [00:26<00:18, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.10G/4.98G [00:26<00:14, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.12G/4.98G [00:26<00:12, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.16G/4.98G [00:27<00:11, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.19G/4.98G [00:27<00:09, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.21G/4.98G [00:27<00:09, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.98G [00:27<00:09, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.25G/4.98G [00:27<00:09, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.28G/4.98G [00:27<00:08, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.31G/4.98G [00:27<00:08, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.33G/4.98G [00:27<00:08, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.36G/4.98G [00:28<00:08, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.98G [00:28<00:07, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.98G [00:28<00:07, 214MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.98G [00:31<00:59, 25.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.98G [00:31<00:41, 36.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.50G/4.98G [00:31<00:32, 44.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.53G/4.98G [00:32<00:23, 60.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.57G/4.98G [00:32<00:17, 79.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.98G [00:32<00:14, 98.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.98G [00:32<00:12, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.65G/4.98G [00:32<00:10, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.68G/4.98G [00:32<00:08, 151MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.98G [00:32<00:07, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.74G/4.98G [00:33<00:06, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.98G [00:33<00:06, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.81G/4.98G [00:33<00:06, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.98G [00:33<00:05, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.87G/4.98G [00:33<00:05, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.90G/4.98G [00:33<00:05, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.98G [00:33<00:04, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.96G/4.98G [00:35<00:20, 50.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.98G/4.98G [00:35<00:16, 60.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.98G [00:35<00:12, 79.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/4.98G [00:36<00:09, 100MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.07G/4.98G [00:36<00:08, 111MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.10G/4.98G [00:36<00:06, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.98G [00:36<00:05, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.15G/4.98G [00:36<00:05, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.98G [00:36<00:04, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.98G [00:36<00:04, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/4.98G [00:37<00:03, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.28G/4.98G [00:37<00:03, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.31G/4.98G [00:37<00:03, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.33G/4.98G [00:37<00:05, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.35G/4.98G [00:37<00:05, 112MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.37G/4.98G [00:38<00:06, 92.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.39G/4.98G [00:38<00:06, 92.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.98G [00:38<00:05, 97.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.44G/4.98G [00:38<00:04, 115MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.47G/4.98G [00:39<00:04, 128MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.98G [00:39<00:05, 86.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.98G [00:39<00:05, 82.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.98G [00:39<00:06, 76.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.54G/4.98G [00:40<00:04, 88.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.56G/4.98G [00:40<00:05, 76.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.98G [00:40<00:04, 94.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.98G [00:40<00:02, 122MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.65G/4.98G [00:40<00:02, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.67G/4.98G [00:40<00:01, 157MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.70G/4.98G [00:41<00:01, 173MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.73G/4.98G [00:41<00:01, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.76G/4.98G [00:41<00:01, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.98G [00:41<00:01, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.98G [00:41<00:00, 202MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.84G/4.98G [00:41<00:00, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.88G/4.98G [00:41<00:00, 209MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.91G/4.98G [00:42<00:00, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.94G/4.98G [00:42<00:00, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.98G/4.98G [00:42<00:00, 117MB/s]\n",
            "Downloading shards:  50% 1/2 [00:42<00:42, 42.79s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/1.15G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 10.5M/1.15G [00:00<00:16, 70.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 21.0M/1.15G [00:00<00:13, 86.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 31.5M/1.15G [00:00<00:12, 88.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 41.9M/1.15G [00:00<00:13, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 52.4M/1.15G [00:00<00:19, 57.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 83.9M/1.15G [00:00<00:11, 95.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   8% 94.4M/1.15G [00:01<00:11, 93.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 105M/1.15G [00:01<00:11, 91.5MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 115M/1.15G [00:01<00:11, 89.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  11% 126M/1.15G [00:01<00:11, 88.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 136M/1.15G [00:01<00:11, 87.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 147M/1.15G [00:01<00:11, 87.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  14% 157M/1.15G [00:01<00:11, 86.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 168M/1.15G [00:01<00:11, 86.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 178M/1.15G [00:02<00:11, 86.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 189M/1.15G [00:02<00:11, 86.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 199M/1.15G [00:02<00:10, 87.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 210M/1.15G [00:02<00:12, 75.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 220M/1.15G [00:02<00:12, 75.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 231M/1.15G [00:02<00:11, 80.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 241M/1.15G [00:02<00:11, 82.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 252M/1.15G [00:02<00:10, 82.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  23% 262M/1.15G [00:03<00:10, 84.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 273M/1.15G [00:03<00:10, 85.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 283M/1.15G [00:03<00:10, 86.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 294M/1.15G [00:03<00:09, 86.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 304M/1.15G [00:03<00:09, 85.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 315M/1.15G [00:03<00:09, 85.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 325M/1.15G [00:03<00:09, 85.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 336M/1.15G [00:03<00:09, 84.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  30% 346M/1.15G [00:04<00:09, 86.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 357M/1.15G [00:04<00:09, 86.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 367M/1.15G [00:04<00:09, 84.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 377M/1.15G [00:04<00:09, 84.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 388M/1.15G [00:04<00:08, 85.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 398M/1.15G [00:04<00:08, 87.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 409M/1.15G [00:04<00:08, 87.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 419M/1.15G [00:04<00:08, 86.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 430M/1.15G [00:05<00:08, 86.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 440M/1.15G [00:05<00:08, 86.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 451M/1.15G [00:05<00:08, 86.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 461M/1.15G [00:05<00:08, 80.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 472M/1.15G [00:05<00:08, 81.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 482M/1.15G [00:05<00:08, 82.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 493M/1.15G [00:05<00:07, 83.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 503M/1.15G [00:05<00:07, 83.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 514M/1.15G [00:06<00:07, 84.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 524M/1.15G [00:06<00:07, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 535M/1.15G [00:06<00:07, 85.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 545M/1.15G [00:06<00:07, 85.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 556M/1.15G [00:06<00:07, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 566M/1.15G [00:07<00:16, 35.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 587M/1.15G [00:07<00:10, 56.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  53% 608M/1.15G [00:07<00:06, 78.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 640M/1.15G [00:07<00:04, 114MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 661M/1.15G [00:07<00:04, 111MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 682M/1.15G [00:08<00:04, 102MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 703M/1.15G [00:08<00:04, 96.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 724M/1.15G [00:08<00:04, 93.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 744M/1.15G [00:08<00:04, 90.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 755M/1.15G [00:08<00:04, 90.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 765M/1.15G [00:09<00:04, 84.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 776M/1.15G [00:09<00:04, 82.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 786M/1.15G [00:09<00:04, 85.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 797M/1.15G [00:09<00:04, 87.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 807M/1.15G [00:09<00:03, 86.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 818M/1.15G [00:09<00:03, 86.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 828M/1.15G [00:09<00:03, 86.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 839M/1.15G [00:09<00:03, 86.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 849M/1.15G [00:10<00:03, 85.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 860M/1.15G [00:10<00:04, 61.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 870M/1.15G [00:10<00:04, 63.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 881M/1.15G [00:10<00:05, 54.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 891M/1.15G [00:10<00:05, 49.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 902M/1.15G [00:11<00:04, 53.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 912M/1.15G [00:11<00:04, 48.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 923M/1.15G [00:11<00:04, 49.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 933M/1.15G [00:11<00:04, 52.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  82% 944M/1.15G [00:11<00:03, 55.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 954M/1.15G [00:12<00:03, 51.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 965M/1.15G [00:12<00:03, 59.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 986M/1.15G [00:12<00:01, 87.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 1.02G/1.15G [00:12<00:01, 125MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 1.04G/1.15G [00:12<00:00, 119MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 1.06G/1.15G [00:12<00:00, 106MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 1.08G/1.15G [00:13<00:00, 99.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  96% 1.10G/1.15G [00:13<00:00, 92.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 1.11G/1.15G [00:13<00:00, 91.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 1.12G/1.15G [00:13<00:00, 89.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 1.13G/1.15G [00:13<00:00, 88.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 1.15G/1.15G [00:14<00:00, 81.8MB/s]\n",
            "Downloading shards: 100% 2/2 [00:57<00:00, 28.56s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:18<00:00,  9.07s/it]\n",
            "generation_config.json: 100% 168/168 [00:00<00:00, 1.27MB/s]\n",
            "tokenizer_config.json: 100% 40.6k/40.6k [00:00<00:00, 640kB/s]\n",
            "tokenizer.model: 100% 4.24M/4.24M [00:00<00:00, 18.4MB/s]\n",
            "tokenizer.json: 100% 17.5M/17.5M [00:00<00:00, 59.7MB/s]\n",
            "special_tokens_map.json: 100% 522/522 [00:00<00:00, 3.63MB/s]\n",
            "Model initialized.\n",
            "  0% 0/5400 [00:00<?, ?it/s]Error in model request: Expecting value: line 1 column 1 (char 0)\n",
            "  0% 1/5400 [00:15<23:18:37, 15.54s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/script_MC_new.py\", line 200, in <module>\n",
            "    main(args.excel_path, args.category, args.model)\n",
            "  File \"/content/script_MC_new.py\", line 191, in main\n",
            "    process_sheet(df, category, model, json_filename, text_gen_pipeline)\n",
            "  File \"/content/script_MC_new.py\", line 117, in process_sheet\n",
            "    response = text_gen_pipeline(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\", line 257, in __call__\n",
            "    return super().__call__(Chat(text_inputs), **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1254, in __call__\n",
            "    return self.run_single(inputs, preprocess_params, forward_params, postprocess_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1261, in run_single\n",
            "    model_outputs = self.forward(model_inputs, **forward_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py\", line 1161, in forward\n",
            "    model_outputs = self._forward(model_inputs, **forward_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/pipelines/text_generation.py\", line 349, in _forward\n",
            "    generated_sequence = self.model.generate(input_ids=input_ids, attention_mask=attention_mask, **generate_kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1914, in generate\n",
            "    result = self._sample(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 2651, in _sample\n",
            "    outputs = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 169, in new_forward\n",
            "    output = module._old_forward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gemma2/modeling_gemma2.py\", line 1073, in forward\n",
            "    outputs = self.model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 169, in new_forward\n",
            "    output = module._old_forward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gemma2/modeling_gemma2.py\", line 913, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 169, in new_forward\n",
            "    output = module._old_forward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gemma2/modeling_gemma2.py\", line 655, in forward\n",
            "    hidden_states, self_attn_weights, present_key_value = self.self_attn(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 169, in new_forward\n",
            "    output = module._old_forward(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gemma2/modeling_gemma2.py\", line 550, in forward\n",
            "    value_states = self.v_proj(hidden_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 164, in new_forward\n",
            "    args, kwargs = module._hf_hook.pre_forward(module, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/hooks.py\", line 363, in pre_forward\n",
            "    return send_to_device(args, self.execution_device), send_to_device(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 183, in send_to_device\n",
            "    {\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/operations.py\", line 183, in <dictcomp>\n",
            "    {\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}